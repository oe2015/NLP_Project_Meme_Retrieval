{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Load Dataset and Split it into training Validation and Test***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kareem/anaconda3/envs/NLP_Project/lib/python3.12/site-packages (from datasets) (2.1.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /home/kareem/anaconda3/envs/NLP_Project/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.10.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /home/kareem/anaconda3/envs/NLP_Project/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.16.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (63 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kareem/anaconda3/envs/NLP_Project/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.32.2->datasets)\n",
      "  Downloading charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kareem/anaconda3/envs/NLP_Project/lib/python3.12/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kareem/anaconda3/envs/NLP_Project/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/kareem/anaconda3/envs/NLP_Project/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/kareem/anaconda3/envs/NLP_Project/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets)\n",
      "  Downloading propcache-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.10.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading yarl-1.16.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
      "Downloading propcache-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (248 kB)\n",
      "Installing collected packages: xxhash, urllib3, tqdm, pyyaml, pyarrow, propcache, multidict, idna, fsspec, frozenlist, filelock, dill, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, multiprocess, aiosignal, huggingface-hub, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 datasets-3.0.2 dill-0.3.8 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.26.1 idna-3.10 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.0 pyarrow-17.0.0 pyyaml-6.0.2 requests-2.32.3 tqdm-4.66.5 urllib3-2.2.3 xxhash-3.5.0 yarl-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk, DatasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"./Dataset/full_meme_cap_ocr\")\n",
    "\n",
    "def get_ocr_text_list(split):\n",
    "    # Join the \"labels\" text within each dictionary in \"extracted_text\", or use \"\" if labels are None\n",
    "    ocr_texts = [\n",
    "        \" \".join(label for label in item.get(\"<OCR_WITH_REGION>\", {}).get(\"labels\", []) if label is not None)\n",
    "        if item.get(\"<OCR_WITH_REGION>\") and item[\"<OCR_WITH_REGION>\"][\"labels\"] is not None\n",
    "        else \"\"\n",
    "        for item in split[\"extracted_text\"]\n",
    "    ]\n",
    "    return ocr_texts\n",
    "\n",
    "\n",
    "# Add a column with ocr extracted text\n",
    "dataset = dataset.add_column(\"OCR_text\", get_ocr_text_list(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'memes',\n",
       " 'img_captions': ['Two men in brown vests are standing outside.'],\n",
       " 'meme_captions': ['Meme poster will say Kanye is a klan member from a sketch rather than himself.',\n",
       "  'Meme poster will tell the kids Kanye was just as much of a white supremacist as a klan member.',\n",
       "  'The poster is making fun of the black man and saying they are going to tell their children in the future that he was Kanye.',\n",
       "  'Poster vows to present Ye as a racist in the future.'],\n",
       " 'title': 'The Ye Reicht',\n",
       " 'url': 'https://farm66.staticflickr.com/65535/52761419771_382d97602b.png',\n",
       " 'img_fname': 'memes_zap0cv.png',\n",
       " 'metaphors': [{'meaning': 'Dave Chapelle Klan Character and white klan member',\n",
       "   'metaphor': 'Two men'}],\n",
       " 'post_id': 'zap0cv',\n",
       " 'extracted_text': {'<OCR_WITH_REGION>': {'labels': ['</s>Gonna tell future generations this was',\n",
       "    'Kanye'],\n",
       "   'quad_boxes': [[18.04800033569336,\n",
       "     0.10649999976158142,\n",
       "     640.89599609375,\n",
       "     0.10649999976158142,\n",
       "     640.89599609375,\n",
       "     0.2685000002384186,\n",
       "     18.04800033569336,\n",
       "     0.265500009059906],\n",
       "    [18.04800033569336,\n",
       "     0.2985000014305115,\n",
       "     124.03199768066406,\n",
       "     0.3075000047683716,\n",
       "     123.26399993896484,\n",
       "     0.4634999930858612,\n",
       "     17.280000686645508,\n",
       "     0.4544999897480011]]}},\n",
       " 'OCR_text': '</s>Gonna tell future generations this was Kanye'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[160]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Preprocess contextual meme_caption and OCR_text columns***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages (from nltk) (4.66.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/kareem.elzeky/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kareem.elzeky/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/kareem.elzeky/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/kareem.elzeky/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/kareem.elzeky/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "\n",
    "import nltk\n",
    "# Ensure NLTK resources are available\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    # Replace <s> with an empty string\n",
    "    text = text.replace('</s>', '')  \n",
    "\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "   \n",
    "    # Tokenize\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply cleaning to the relevant columns\n",
    "def preprocess(dataset):\n",
    "    dataset = dataset.map(lambda x: {\n",
    "        'cleaned_meme_captions': clean_text(\" \".join(x['meme_captions'])),\n",
    "        'cleaned_OCR': clean_text(x['OCR_text'])\n",
    "    })\n",
    "    return dataset\n",
    "\n",
    "# Preprocess the dataset\n",
    "dataset = preprocess(dataset)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['category', 'img_captions', 'meme_captions', 'title', 'url', 'img_fname', 'metaphors', 'post_id', 'extracted_text', 'OCR_text', 'cleaned_meme_captions', 'cleaned_OCR'],\n",
       "    num_rows: 6382\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset to remove any rows with empty meme captions or OCR text\n",
    "dataset = dataset.filter(lambda x: x['cleaned_meme_captions'] != '' and x['cleaned_OCR'] != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5754"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Split the dataset with clean contextual captions and OCR texts and save the splits***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4603\n",
      "Validation size: 575\n",
      "Test size: 576\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "train_val_test = dataset.train_test_split(test_size=0.2, seed=42)  # 80% train, 20% val+test\n",
    "train_set = train_val_test[\"train\"]\n",
    "val_test = train_val_test[\"test\"]\n",
    "\n",
    "# Further split val+test to get validation and test sets\n",
    "val_test_split = val_test.train_test_split(test_size=0.5, seed=42)  # 50% of val+test each\n",
    "val_set = val_test_split[\"train\"]\n",
    "test_set = val_test_split[\"test\"]\n",
    "\n",
    "# Now you have train, validation, and test sets\n",
    "print(f\"Train size: {len(train_set)}\")\n",
    "print(f\"Validation size: {len(val_set)}\")\n",
    "print(f\"Test size: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_set,\n",
    "    \"validation\": val_set,\n",
    "    \"test\": test_set\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (0/1 shards):   0%|          | 0/5105 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 5105/5105 [00:00<00:00, 13578.07 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 638/638 [00:00<00:00, 15717.58 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 639/639 [00:00<00:00, 15415.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with splits and new 'OCR_text and embeddings' columns saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_dict.save_to_disk(\"./Dataset/meme_cap_splits_with_ocr_text\")\n",
    "\n",
    "print(\"Dataset with splits and new 'OCR_text' columns saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Load the dataset splits with cleaned contextual captions and OCR texts***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset_dict = load_from_disk(\"./Dataset/meme_cap_splits_with_ocr_text_and_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset_dict[\"train\"]\n",
    "val_set = dataset_dict[\"validation\"]\n",
    "test_set = dataset_dict[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create triplets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Number of GPUs: 1\n",
      "Current CUDA device: 0\n",
      "CUDA device name: Quadro RTX 6000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Create Triplets\n",
    "def create_triplets(dataset, k=5):\n",
    "    triplets = []\n",
    "    all_OCR_texts = dataset['cleaned_OCR']  # Extract all OCR texts for random selection\n",
    "    \n",
    "    for idx in range(len(dataset)):\n",
    "        anchor = dataset[idx]['cleaned_meme_captions']\n",
    "        positive = dataset[idx]['cleaned_OCR']\n",
    "        \n",
    "        # Ensure that the negatives are selected from different entries\n",
    "        negatives = set()\n",
    "        while len(negatives) < k:\n",
    "            negative = random.choice(all_OCR_texts)\n",
    "            if negative != positive and negative != anchor:  # Ensure the negative is not the same as positive or anchor\n",
    "                negatives.add(negative)\n",
    "        \n",
    "        # Create triplets\n",
    "        for negative in negatives:\n",
    "            triplets.append([anchor, positive, negative])\n",
    "    \n",
    "    return triplets\n",
    "\n",
    "# Generate triplets for training and validation\n",
    "triplet_data_train = create_triplets(train_set, k=1)\n",
    "triplet_data_val = create_triplets(val_set, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_data_train[0]\n",
    "tiplet_data_test = create_triplets(test_set, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Define column names\n",
    "columns = [\"anchor\", \"positive\", \"negative\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transform data into dictionaries\n",
    "train_dict = {col: [row[i] for row in triplet_data_train] for i, col in enumerate(columns)}\n",
    "val_dict = {col: [row[i] for row in triplet_data_val] for i, col in enumerate(columns)}\n",
    "test_dict = {col: [row[i] for row in tiplet_data_test] for i, col in enumerate(columns)}\n",
    "\n",
    "# Create individual datasets using the datasets module directly\n",
    "train_dataset = Dataset.from_dict(train_dict)\n",
    "val_dataset = Dataset.from_dict(val_dict)\n",
    "test_dataset = Dataset.from_dict(test_dict)\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 46030/46030 [00:00<00:00, 1252896.37 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 5750/5750 [00:00<00:00, 256806.88 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 5760/5760 [00:00<00:00, 616180.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_dict.save_to_disk(\"./Dataset/triplet_datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Load triplet datasets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "triplets_dict = load_from_disk(\"./Dataset/triplet_datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative'],\n",
       "        num_rows: 4603\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative'],\n",
       "        num_rows: 575\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative'],\n",
       "        num_rows: 576\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = triplets_dict[\"train\"]\n",
    "eval_dataset = triplets_dict[\"validation\"]\n",
    "test_dataset = triplets_dict[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Evaluating using Recall@k and MRR***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['cleaned_meme_captions']\n",
    "test_set['cleaned_OCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def evaluate_top_k(captions, ocr_texts, model_path, k=5):\n",
    "    \"\"\"\n",
    "    Evaluates the model's performance in retrieving OCR text given captions using top-k retrieval.\n",
    "    \n",
    "    Parameters:\n",
    "    captions (list of str): List of caption texts.\n",
    "    ocr_texts (list of str): List of OCR texts corresponding to each caption.\n",
    "    model_path (str): Path to the fine-tuned SentenceTransformer model.\n",
    "    k (int): Number of top candidates to consider for retrieval.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing Recall@k, MRR, and MAP@k.\n",
    "    \"\"\"\n",
    "    # Load the fine-tuned model\n",
    "    model = SentenceTransformer(model_path)\n",
    "\n",
    "    # Encode captions and OCR texts\n",
    "    caption_embeddings = model.encode(captions, convert_to_tensor=True).cpu().numpy()\n",
    "    ocr_embeddings = model.encode(ocr_texts, convert_to_tensor=True).cpu().numpy()\n",
    "\n",
    "    # Initialize counters for metrics\n",
    "    top_k_hits = 0  # For Recall@k\n",
    "    reciprocal_ranks = []\n",
    " \n",
    "\n",
    "    # Evaluate each caption\n",
    "    for idx, caption_embedding in enumerate(caption_embeddings):\n",
    "        # Compute cosine similarity with all OCR embeddings\n",
    "        similarities = cosine_similarity([caption_embedding], ocr_embeddings).flatten()\n",
    "\n",
    "        # Get indices of the top-k highest similarity scores\n",
    "        top_k_indices = np.argsort(similarities)[-k:][::-1]  # Sort in descending order\n",
    "\n",
    "        # Check if the correct OCR is in the top-k\n",
    "        if idx in top_k_indices:\n",
    "            top_k_hits += 1  # Count for Recall@k\n",
    "\n",
    "            # Compute reciprocal rank for MRR\n",
    "            rank = np.where(top_k_indices == idx)[0][0] + 1  # 1-based rank\n",
    "            reciprocal_ranks.append(1 / rank)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            reciprocal_ranks.append(0)  # No relevant item in top-k\n",
    "\n",
    "    # Calculate Recall@k, MRR, and MAP@k\n",
    "    recall_at_k = top_k_hits / len(captions)\n",
    "    mrr = np.mean(reciprocal_ranks)\n",
    "\n",
    "    return {\n",
    "        \"recall@k\": recall_at_k,\n",
    "        \"mrr\": mrr,\n",
    "    }\n",
    "\n",
    "\n",
    "# # Example lists of captions and OCR texts\n",
    "# captions = test_set['cleaned_meme_captions'] # List of captions\n",
    "# ocr_texts = test_set['cleaned_OCR']  # List of OCR texts corresponding to captions\n",
    "# model_path = \"models/mpnet-base-caption-ocr-triplet/final2\"\n",
    "\n",
    "\n",
    "\n",
    "# metrics = evaluate_top_k(captions, ocr_texts, model_path, k=5)\n",
    "\n",
    "# print(f\"Recall@5: {metrics['recall@k'] * 100:.2f}%\")\n",
    "# print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")\n",
    "# print(f\"Mean Average Precision at 5 (MAP@5): {metrics['map@k']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Vanilla Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 54.34%\n",
      "Mean Reciprocal Rank (MRR): 0.5434\n"
     ]
    }
   ],
   "source": [
    "\n",
    "captions = test_set['cleaned_meme_captions'] # List of captions\n",
    "ocr_texts = test_set['cleaned_OCR']  # List of OCR texts corresponding to captions\n",
    "model_path = \"all-mpnet-base-v2\"\n",
    "\n",
    "metrics = evaluate_top_k(captions, ocr_texts, model_path, k=1)\n",
    "\n",
    "print(f\"Recall@1: {metrics['recall@k'] * 100:.2f}%\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5: 71.35%\n",
      "Mean Reciprocal Rank (MRR): 0.6064\n"
     ]
    }
   ],
   "source": [
    "captions = test_set['cleaned_meme_captions'] # List of captions\n",
    "ocr_texts = test_set['cleaned_OCR']  # List of OCR texts corresponding to captions\n",
    "model_path = \"all-mpnet-base-v2\"\n",
    "\n",
    "metrics = evaluate_top_k(captions, ocr_texts, model_path, k=5)\n",
    "\n",
    "print(f\"Recall@5: {metrics['recall@k'] * 100:.2f}%\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 76.39%\n",
      "Mean Reciprocal Rank (MRR): 0.6132\n"
     ]
    }
   ],
   "source": [
    "captions = test_set['cleaned_meme_captions'] # List of captions\n",
    "ocr_texts = test_set['cleaned_OCR']  # List of OCR texts corresponding to captions\n",
    "model_path = \"all-mpnet-base-v2\"\n",
    "\n",
    "metrics = evaluate_top_k(captions, ocr_texts, model_path, k=10)\n",
    "\n",
    "print(f\"Recall@10: {metrics['recall@k'] * 100:.2f}%\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Training sentence transformer model using Triplet Loss***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='720' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [720/720 08:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Caption-ocr-dev Cosine Accuracy</th>\n",
       "      <th>Caption-ocr-dev Dot Accuracy</th>\n",
       "      <th>Caption-ocr-dev Manhattan Accuracy</th>\n",
       "      <th>Caption-ocr-dev Euclidean Accuracy</th>\n",
       "      <th>Caption-ocr-dev Max Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.738400</td>\n",
       "      <td>4.707828</td>\n",
       "      <td>0.958261</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>0.961739</td>\n",
       "      <td>0.958261</td>\n",
       "      <td>0.961739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.721000</td>\n",
       "      <td>4.694885</td>\n",
       "      <td>0.958261</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>0.963478</td>\n",
       "      <td>0.958261</td>\n",
       "      <td>0.963478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.714800</td>\n",
       "      <td>4.684834</td>\n",
       "      <td>0.963478</td>\n",
       "      <td>0.036522</td>\n",
       "      <td>0.961739</td>\n",
       "      <td>0.963478</td>\n",
       "      <td>0.963478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.703600</td>\n",
       "      <td>4.677135</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.033043</td>\n",
       "      <td>0.961739</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.966957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.697700</td>\n",
       "      <td>4.671768</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.033043</td>\n",
       "      <td>0.961739</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.966957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.698300</td>\n",
       "      <td>4.668466</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.033043</td>\n",
       "      <td>0.961739</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.966957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.692000</td>\n",
       "      <td>4.667116</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.033043</td>\n",
       "      <td>0.961739</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.966957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "\n",
    "\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    losses\n",
    ")\n",
    "\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\").to(device)\n",
    "\n",
    "\n",
    "loss = losses.TripletLoss(model=model)\n",
    "\n",
    "\n",
    "dev_evaluator = TripletEvaluator(\n",
    "    anchors=eval_dataset[\"anchor\"],\n",
    "    positives=eval_dataset[\"positive\"],\n",
    "    negatives=eval_dataset[\"negative\"],\n",
    "    name=\"caption-ocr-dev\",\n",
    ")\n",
    "dev_evaluator(model)\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/caption-ocr-triplet\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=1e-7,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    # run_name=\"mpnet-base-all-nli-triplet\",  # Will be used in W&B if `wandb` is installed\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=dev_evaluator,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# 8. Save the trained model\n",
    "model.save_pretrained(\"models/mpnet-base-caption-ocr-triplet/final2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mpnet-caption-ocr-test_cosine_accuracy': 0.9618055555555556,\n",
       " 'mpnet-caption-ocr-test_dot_accuracy': 0.03819444444444445,\n",
       " 'mpnet-caption-ocr-test_manhattan_accuracy': 0.953125,\n",
       " 'mpnet-caption-ocr-test_euclidean_accuracy': 0.9618055555555556,\n",
       " 'mpnet-caption-ocr-test_max_accuracy': 0.9618055555555556}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Optional) Evaluate the trained model on the test set\n",
    "test_evaluator = TripletEvaluator(\n",
    "    anchors=test_dataset[\"anchor\"],\n",
    "    positives=test_dataset[\"positive\"],\n",
    "    negatives=test_dataset[\"negative\"],\n",
    "    name=\"mpnet-caption-ocr-test\",\n",
    ")\n",
    "test_evaluator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model fine-tuned with Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 56.77%\n",
      "Mean Reciprocal Rank (MRR): 0.5677\n"
     ]
    }
   ],
   "source": [
    "# Example lists of captions and OCR texts\n",
    "captions = test_set['cleaned_meme_captions'] # List of captions\n",
    "ocr_texts = test_set['cleaned_OCR']  # List of OCR texts corresponding to captions\n",
    "model_path = \"models/mpnet-base-caption-ocr-triplet/final2\"\n",
    "\n",
    "metrics = evaluate_top_k(captions, ocr_texts, model_path, k=1)\n",
    "\n",
    "print(f\"Recall@1: {metrics['recall@k'] * 100:.2f}%\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5: 76.04%\n",
      "Mean Reciprocal Rank (MRR): 0.6437\n"
     ]
    }
   ],
   "source": [
    "# Example lists of captions and OCR texts\n",
    "captions = test_set['cleaned_meme_captions'] # List of captions\n",
    "ocr_texts = test_set['cleaned_OCR']  # List of OCR texts corresponding to captions\n",
    "model_path = \"models/mpnet-base-caption-ocr-triplet/final2\"\n",
    "\n",
    "metrics = evaluate_top_k(captions, ocr_texts, model_path, k=5)\n",
    "\n",
    "print(f\"Recall@5: {metrics['recall@k'] * 100:.2f}%\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 79.86%\n",
      "Mean Reciprocal Rank (MRR): 0.6487\n"
     ]
    }
   ],
   "source": [
    "# Example lists of captions and OCR texts\n",
    "captions = test_set['cleaned_meme_captions'] # List of captions\n",
    "ocr_texts = test_set['cleaned_OCR']  # List of OCR texts corresponding to captions\n",
    "model_path = \"models/mpnet-base-caption-ocr-triplet/final2\"\n",
    "\n",
    "metrics = evaluate_top_k(captions, ocr_texts, model_path, k=10)\n",
    "\n",
    "print(f\"Recall@10: {metrics['recall@k'] * 100:.2f}%\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Train using Multiple Negative Ranking Loss***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kareem.elzeky/.conda/envs/NLP_meme-project/lib/python3.12/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='720' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [720/720 11:27, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>All-captions-ocr-dev-8 Cosine Accuracy</th>\n",
       "      <th>All-captions-ocr-dev-8 Dot Accuracy</th>\n",
       "      <th>All-captions-ocr-dev-8 Manhattan Accuracy</th>\n",
       "      <th>All-captions-ocr-dev-8 Euclidean Accuracy</th>\n",
       "      <th>All-captions-ocr-dev-8 Max Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.052500</td>\n",
       "      <td>0.811410</td>\n",
       "      <td>0.977391</td>\n",
       "      <td>0.022609</td>\n",
       "      <td>0.968696</td>\n",
       "      <td>0.977391</td>\n",
       "      <td>0.977391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.808900</td>\n",
       "      <td>0.768663</td>\n",
       "      <td>0.975652</td>\n",
       "      <td>0.024348</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.975652</td>\n",
       "      <td>0.975652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.760705</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.970435</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.973913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.581600</td>\n",
       "      <td>0.768794</td>\n",
       "      <td>0.975652</td>\n",
       "      <td>0.024348</td>\n",
       "      <td>0.966957</td>\n",
       "      <td>0.975652</td>\n",
       "      <td>0.975652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.514300</td>\n",
       "      <td>0.760745</td>\n",
       "      <td>0.979130</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>0.970435</td>\n",
       "      <td>0.979130</td>\n",
       "      <td>0.979130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.428200</td>\n",
       "      <td>0.766439</td>\n",
       "      <td>0.972174</td>\n",
       "      <td>0.027826</td>\n",
       "      <td>0.968696</td>\n",
       "      <td>0.972174</td>\n",
       "      <td>0.972174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.419600</td>\n",
       "      <td>0.766241</td>\n",
       "      <td>0.972174</td>\n",
       "      <td>0.027826</td>\n",
       "      <td>0.968696</td>\n",
       "      <td>0.972174</td>\n",
       "      <td>0.972174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1. Load a model to finetune with 2. (Optional) model card data\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\").to(device)\n",
    "\n",
    "\n",
    "# 4. Define a loss function\n",
    "loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# 5. (Optional) Specify training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/mpnet-base-all-captions-triplet-8\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=8,\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
    "    metric_for_best_model=\"eval_all-captions-ocr-dev-8_max_accuracy\",  # Choose the metric to monitor (e.g., \"accuracy\")\n",
    "    greater_is_better=True,  # Set to False if lower values are better (e.g., for loss)\n",
    "\n",
    "    run_name=\"mpnet-base-all-captions-ocr-triplet-8\",  # Will be used in W&B if `wandb` is installed\n",
    ")\n",
    "\n",
    "# 6. (Optional) Create an evaluator & evaluate the base model\n",
    "dev_evaluator = TripletEvaluator(\n",
    "    anchors=eval_dataset[\"anchor\"],\n",
    "    positives=eval_dataset[\"positive\"],\n",
    "    negatives=eval_dataset[\"negative\"],\n",
    "    name=\"all-captions-ocr-dev-8\",\n",
    ")\n",
    "dev_evaluator(model)\n",
    "\n",
    "# 7. Create a trainer & train\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=dev_evaluator,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# 8. Save the trained model\n",
    "model.save_pretrained(\"models/mpnet-base-all-caption-ocr-triplet/final8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mpnet-caption-ocr-test_cosine_accuracy': 0.9652777777777778,\n",
       " 'mpnet-caption-ocr-test_dot_accuracy': 0.034722222222222224,\n",
       " 'mpnet-caption-ocr-test_manhattan_accuracy': 0.9670138888888888,\n",
       " 'mpnet-caption-ocr-test_euclidean_accuracy': 0.9652777777777778,\n",
       " 'mpnet-caption-ocr-test_max_accuracy': 0.9670138888888888}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    losses\n",
    ")\n",
    "\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"models/mpnet-base-all-caption-ocr-triplet/final8\")\n",
    "# (Optional) Evaluate the trained model on the test set\n",
    "test_evaluator = TripletEvaluator(\n",
    "    anchors=test_dataset[\"anchor\"],\n",
    "    positives=test_dataset[\"positive\"],\n",
    "    negatives=test_dataset[\"negative\"],\n",
    "    name=\"mpnet-caption-ocr-test\",\n",
    ")\n",
    "test_evaluator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model fine-tuned with Multiple Negative Ranking Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 67.19%\n",
      "Mean Reciprocal Rank (MRR): 0.6719\n"
     ]
    }
   ],
   "source": [
    "# Example lists of captions and OCR texts\n",
    "captions = test_set['cleaned_meme_captions'] # List of captions\n",
    "ocr_texts = test_set['cleaned_OCR']  # List of OCR texts corresponding to captions\n",
    "model_path = \"models/mpnet-base-all-caption-ocr-triplet/final8\"\n",
    "\n",
    "metrics = evaluate_top_k(captions, ocr_texts, model_path, k=1)\n",
    "\n",
    "print(f\"Recall@1: {metrics['recall@k'] * 100:.2f}%\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5: 79.69%\n",
      "Mean Reciprocal Rank (MRR): 0.7198\n"
     ]
    }
   ],
   "source": [
    "# Example lists of captions and OCR texts\n",
    "captions = test_set['cleaned_meme_captions'] # List of captions\n",
    "ocr_texts = test_set['cleaned_OCR']  # List of OCR texts corresponding to captions\n",
    "model_path = \"models/mpnet-base-all-caption-ocr-triplet/final8\"\n",
    "\n",
    "metrics = evaluate_top_k(captions, ocr_texts, model_path, k=5)\n",
    "\n",
    "print(f\"Recall@5: {metrics['recall@k'] * 100:.2f}%\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 84.20%\n",
      "Mean Reciprocal Rank (MRR): 0.7258\n"
     ]
    }
   ],
   "source": [
    "# Example lists of captions and OCR texts\n",
    "captions = test_set['cleaned_meme_captions'] # List of captions\n",
    "ocr_texts = test_set['cleaned_OCR']  # List of OCR texts corresponding to captions\n",
    "model_path = \"models/mpnet-base-all-caption-ocr-triplet/final8\"\n",
    "\n",
    "metrics = evaluate_top_k(captions, ocr_texts, model_path, k=10)\n",
    "\n",
    "print(f\"Recall@10: {metrics['recall@k'] * 100:.2f}%\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
